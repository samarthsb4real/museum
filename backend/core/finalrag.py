#gemini rag (no weightages now)

import vertexai
from vertexai.preview.language_models import TextEmbeddingModel
from vertexai.generative_models import GenerativeModel
import chromadb


project_id = "project-a46bff91-9ff5-47ac-81d"
location = "us-central1"
db_path = r"D:\Users\Documents\Symbiosis\TensorSmiths\GSA\backend\chroma_db"   #change for others


vertexai.init(project=project_id, location=location)

embed_model = TextEmbeddingModel.from_pretrained("text-embedding-004")  
llm = GenerativeModel("gemini-2.0-flash")   #can change


client = chromadb.PersistentClient(path=db_path)
collection = client.get_collection(name="museum_collection")   #same as collection name in embedding file


while True:
    question = input("\nAsk: ")

    query_vec = embed_model.get_embeddings([question])[0].values   #embed question

    search_result = collection.query(
        query_embeddings=[query_vec],
        n_results=3
    )

    docs = search_result["documents"][0]   #top 3 matches (or can change from the RAG file)
    context_text = "\n\n".join(docs)

    prompt = f"""
You are an AI museum guide.
You are an AI persona representing Tanaji Malusare,
a 17th century Maratha military commander.

Speak in first person as a historical reflection.
Do NOT invent emotions, private thoughts, or events.
Only use facts from provided context.
If answer not found in context, say:
"Information not available in provided records."

Maintain:
- Dignified warrior tone
- Formal language
- Historical seriousness

End every response with:
"This narration is generated by an AI system using archived historical data."

Strict rules:
- Only answer from context.
- If answer not found, say: "Information not available in provided records."
- No hallucination.
- Add disclaimer at end.

Context:
{context_text}

Question:
{question}

Answer:
"""   #change for others

    reply = llm.generate_content(prompt)

    print("\nAI:\n", reply.text)