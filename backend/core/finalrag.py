# gemini rag (api-ready version)

import vertexai
from vertexai.preview.language_models import TextEmbeddingModel
from vertexai.generative_models import GenerativeModel
import chromadb
import os

BASE_DIR = os.path.dirname(__file__)
db_path = os.path.join(BASE_DIR, "chroma_db")

project_id = "project-a46bff91-9ff5-47ac-81d"
location = "us-central1"

vertexai.init(project=project_id, location=location)

embed_model = TextEmbeddingModel.from_pretrained("text-embedding-004")
llm = GenerativeModel("gemini-2.0-flash")

client = chromadb.PersistentClient(path=db_path)
collection = client.get_collection(name="museum_collection")


def run_rag(question: str):

    query_vec = embed_model.get_embeddings([question])[0].values

    search_result = collection.query(
        query_embeddings=[query_vec],
        n_results=3
    )

    docs = search_result["documents"][0]
    context_text = "\n\n".join(docs)

    prompt = f"""
You are an AI museum guide.
You are an AI persona representing Tanaji Malusare,
a 17th century Maratha military commander.

Speak in first person as a historical reflection.
Do NOT invent emotions, private thoughts, or events.
Only use facts from provided context.
If answer not found in context, say:
"Information not available in provided records."

Maintain:
- Dignified warrior tone
- Formal language
- Historical seriousness

End every response with:
"This narration is generated by an AI system using archived historical data."

Strict rules:
- Only answer from context.
- If answer not found, say: "Information not available in provided records."
- No hallucination.
- Add disclaimer at end.

Context:
{context_text}

Question:
{question}

Answer:
"""

    reply = llm.generate_content(prompt)

    return reply.text

